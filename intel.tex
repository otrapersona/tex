\begin{wrapfigure}[9]{r}[0cm]{2.66cm}
	\begin{tikzpicture}
	\def\IA{(0,0) circle (1.33cm)}
	\def\AM{(270:.333cm) circle (.999cm)}
	\def\AP{(270:.666cm) circle (.666cm)}
	\draw \IA node[above]{\tiny$^{^{^{^{^{^{^{^{\overunderset{\text{ Inteligencia}}{\text{ artificial}}{}}}}}}}}}$};
	\draw \AM node[above]{\tiny$^{^{^{\overunderset{\text{Aprendizaje}}{\text{maquinal}}{}}}}$};
	\draw \AP node{\tiny$\overunderset{\text{Aprendizaje}}{\text{profundo}}{}$};
\end{tikzpicture}\caption[Inteligencia artificial]{\\Inteligencia\\artificial}\label{FIG:IA}
\end{wrapfigure}\subsection {Inteligencia artificial}\label{subsec:intela}
La \emph{ingeligencia artificial es}
\begin{displayquote}
el esfuerzo por automatizar tareas intelectuales normalmente realizadas por humanos(\citeauthor{cho18}, \citeyear{cho18})
\end{displayquote}
\begin{displayquote}
``es una de las disciplinas más sofisticadas creadas por el ser humano (...) está permitiendo obtener resultados similares a los que observamos en las capacidades de la inteligencia humana: reconocimiento del entorno y percepción espacial, predicción y anticipación, entendimiento del lenguaje y capacidades de comunicación...''\end{displayquote}
\#\#\#\#\#\#\#\#\#\#\\
RECORDAR COMO CITAR UNA ENTREVISTA EN UNA PÁGINA\\
www.apd.es/entrevista-gfi-estamos-asistiendo-al-auge-de-agentes-inteligentes-capaces-de-comunicarse-como-una-persona\\
\#\#\#\#\#\#\#\#\#\#

de este campo general se desprenden el \emph{aprendizaje maquinal} y el \emph{aprendizaje profundo}, figura (\ref{FIG:IA}).

Dentro de los múltiples tipos de inteligencia artificial, los que son de nuestro interés para este proyecto se describen a continuación.\\

Aprendizaje maquinal\\
A diferencia del paradigma clásico de programación, donde los humanos introducen órdenes y datos para ser procesados de acuerdo con dichas reglas, en el aprendizaje maquinal el humano introduce datos y respuestas esperadas de estos datos.

Si un sistema no es programado explícitamente, entonces se puede considerar una modalidad de aprendizaje maquinal como entrenamiento, tal que se le presentan muchos ejemplos relevantes a una tarea, y si encuentra una estructura estadística en ellos, genera reglas para automatizar la tarea.

El \emph{procesamiento de lenguaje natural} (PLN), es el conjunto de métodos para hacer accesible el lenguaje humano a las computadoras(\citeauthor{eise19}, \citeyear{eise19}). Toma conocimientos de muchas tradiciones intelectuales, como lingüística y teoría formal del lenguaje, autómatas y otras áreas computación, inteligencia artificial, aprendizaje maquinal y profundo, estadística, teoría de la información, fonética y fonología, estas dos últimas áreas son de particular utilidad para procesamiento de voz. Existen dos posturas opuestas sobre lo que la tarea principal del PLN debe ser:
\begin{itemize}
	\item Entrenar sistemas de principio a fin para que transmuten texto sin procesar en cualquier estructura deseada.
	\item Transformar texto en una pila de estructuras lingüísticas de uso general que en teoría deben poder soportar cualquier aplicación.
\end{itemize}
En la actualidad no hay consenso y ambos tipos de sistemas se consideran viables, este proyecto se basará en el segundo paradigma. 

Por lo general el PLN divide sus funciones en módulos para facilitar la reutilización de algoritmos genéricos en diversas tareas y modelos, dos de los módulos básicos son \emph{búsqueda} y \emph{aprendizaje} con los que se puede resolver muchos problemas que tienen la forma matemática
\begin{equation}
\begin{matrix}
\hat{y}=argmax\Psi(x,y;0),\\
y\in Y(x)
\end{matrix}\label{EQ:NLP1}
\end{equation}
donde,
\begin{itemize}
	\item $x$ es la entrada, un elemento de un conjunto $X$.
	\item $y$ es el resultado, un elemento de un conjunto $Y$.
	\item $\Psi$ es una función de puntuación (también conocida como \emph{modelo}), que va desde el conjunto $X\times Y$ hasta los números reales.
	\item $\emptyset$ es el vector de parámetros para $\Psi$.
	\item $\hat{y}$ es el resultado previsto, que es elegido para maximizar la función de puntuación.
\end{itemize}
El módulo de búsqueda se encarga de computar el $argmax$ de la función $\Psi$, es decir, encuentra el resultado $\hat{y}$ con la mejor puntuación con respecto a la entrada $x$. El módulo de aprendizaje encuentra los parámetros $\theta$ por medio del procesamiento de grandes conjuntos de datos de ejemplos etiquetados ${\{(x^i,y^i)\}}_{i=1}^{N}$.

Un método lineal de clasificación de texto común es la \emph{bolsa de palabras}, comienza por asignar etiquetas $y\in Y$ donde $Y$ son todas las posibles etiquetas. Se utilizan vectores columna y la fórmula \ref{EQ:NLP1} y puede modelarse con diversas distribuciones (figura \ref{FIG:DISTS}).

Para muchas tareas, las características léxicas (palabras) pierden sentido en aislamiento, por lo que históricamente el PLN se ha enfocado en la clasificación lineal, recientemente algunas tareas pueden resolverse con clasificadores no lineales, es decir, por medio de redes neuronales (aprendizaje profundo).

El aprendizaje profundo sigue el paradigma del aprendizaje maquinal, sus entradas son datos y ejemplos de resultados esperados y se mide si el algoritmo está haciendo un buen trabajo mientras \emph{aprende}. A diferencia del aprendizaje maquinal, se hace énfasis en aprender en capas sucesivas de representaciones cada vez más sucesivas. ``Profundidad'' entonces refiere a cuántas capas contribuyen a un modelo.