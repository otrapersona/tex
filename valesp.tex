%\subsubsection{LOTUS}
%La \emph{ley del estadista inconsciente} (\emph{LOTUS}, por sus siglas en inglés) permite calcular $E(g(X))$ directamente usando la distribución de $X$, sin tener que encontrar la distribución de $g(X)$ primero: si $X$ es una variable discreta y $g$ es una función de $\mathbb{R}$ a $\mathbb{R}$, entonces
%\begin{equation}
%E(g(X))=\sum_{x}g(x)P(X=x),
%\end{equation}
%donde la suma se toma de todos los valores posibles de $X$. El valor esperado de $g(X)$ puede ser escrito en forma no agrupado como
%\begin{equation}
%E(g(X))=\sum_{s}g(X(s))p(\{s\}).
%\end{equation}
%\subsubsection{Varianza, agregarlas a la secc que pertenecen}
%Varianza de la geométrica (agregarla a la geom después de editar todo y hacerlo más breve)
%\begin{equation}
%Var(X)=E(X^2)-{(EX)}^2=\frac{q(1+q)}{p^2}-{(\frac{q}{p})}^2=\frac{q}{p^2}
%\end{equation}
%Varianza de la geométrica (lo mismo)
%\begin{equation}
%Var(X)=E(X^2)-{(EX)}^2=(n(n-1)p^2+np)-(np)^2=np(1-p).
%\end{equation}
%Una variable aleatoria $X$ tiene \emph{distribución de Poisson} (denotada $X\sim Pois(\lambda)$) con el parámetro $\lambda$, cuando $\lambda > 0$ si la PMF de $x$ es
%\begin{equation}
%P(X=k)=\frac{e^{-\lambda}\lambda^k}{k!}, k=0,1,2,\ldots.
%\end{equation}
%Varianza de la distribución de Poisson es
%\begin{equation}
%Var(X)=E(X^2)-{(EX)}^2=\lambda(1+\lambda)-\lambda^2=\lambda
%\end{equation}
