\subsection {distribuciones}\label{subsec:dd}
\subsubsection {Binominal geométrica y negativa}
Distribución geométrica: Se tiene una secuencia de ensayos independientes Bernoulli, cada uno con la misma probabilidad de éxito $p\in(0,1)$, con ensayos realizados hasta que se alcanza el éxito. $X$ es el número de \emph{fallas} antes de la primera prueba exitosa por lo que $X$ tiene una \emph{distribución geométrica} con un parámetro $p$; denotado $X\sim Geom(p)$. Con esto podemos llegar a los teoremas de \emph{distribución geométrica de la función de probabilidad}, cuando $X\sim Geom(p)$, entonces la función de probabilidad de $X$ será
\begin{equation}
P(X=k)=q^kp
\end{equation}
para $k=1,2,\ldots,$ cuando $q=1-p$; y el teoremas de \emph{distribución geométrica de la función de distribución acumulativa}, cuando $X\sim Geom(p)$, entonces la función de distribución acumulativa de $X$ será
    \begin{equation}
    F(x)=
    \begin{cases}
    1-q^{\lfloor x\rfloor+1}, \text{ si } x\geq 0;\\
    0, \text{ si }x < 0,
    \end{cases}
    \end{equation}
cuando $q=1-q$ y $\lfloor x\rfloor$ es el mayor entero y menor o igual a $x$.

El valor esperado geométrico de $X\sim Geom(p)$ es
\begin{equation}
E(X)=\sum_{k=0}^{\infty}kq^kp,
\end{equation}
cuando $q=1-p$. Aunque esta no es una serie geométrica, podemos llegar a ello
\begin{equation}\begin{matrix}
\sum_{k=0}^{\infty}q^k=\frac{1}{1-q}\\
\\
\sum_{k=0}^{\infty}kq^{k-1}=\frac{1}{{1-q}^2},
\end{matrix}
\end{equation}
finalmente multiplicamos ambos lados por $pq$, recuperando la suma original que queríamos encontrar
\begin{equation}
E(X)=\sum_{k=0}^{\infty}kq^kp=pq\sum_{k=0}^{\infty}kq^{k-1}=pq\frac{1}{{(1-q)}^2}=\frac{q}{p}.
\end{equation}
Primer valor esperado de éxito \emph{FS}, podemos definir a $Y\sim FS(p)$ como $Y=X+1$ donde $X\sim Geom(p)$, por lo que tenemos
\begin{equation}
E(Y)=E(X+1)=\frac{q}{p}+1=\frac{1}{p}.
\end{equation}

Las \emph{distribuciones binominales negativas} generalizan la distribución geométrica en lugar de esperar por un éxito, podemos esperar por cualquier número predeterminado $r$ de éxitos. En una secuencia de ensayos independientes Bernoulli con probabilidad de éxito $p$, si $X$ es el número de \emph{fallas} antes del éxito número $r$, entonces se dice que $X$tiene una distribución binominal negativa con parámetros $r$ y $p$, denotado $X\sim NBin(r,p)$.

La distribución binominal cuenta el número de éxitos en un número fijo de ensayos, mientras que la binominal negativa cuenta el número de fallas hasta alcanzar cierto número de éxitos. Si $X\sim NBin(r,p)$, entonces la función de probabilidad de $X$ es
\begin{equation}
P(X=n)=\binom{n+r-1}{r-1}p^rq^n
\end{equation}
para $n=0,1,2\ldots,$ donde $q=1=p$.
%\subsubsection{LOTUS}
%La \emph{ley del estadista inconsciente} (\emph{LOTUS}, por sus siglas en inglés) permite calcular $E(g(X))$ directamente usando la distribución de $X$, sin tener que encontrar la distribución de $g(X)$ primero: si $X$ es una variable discreta y $g$ es una función de $\mathbb{R}$ a $\mathbb{R}$, entonces
%\begin{equation}
%E(g(X))=\sum_{x}g(x)P(X=x),
%\end{equation}
%donde la suma se toma de todos los valores posibles de $X$. El valor esperado de $g(X)$ puede ser escrito en forma no agrupado como
%\begin{equation}
%E(g(X))=\sum_{s}g(X(s))p(\{s\}).
%\end{equation}
%\subsubsection{Varianza, agregarlas a la secc que pertenecen}
%Varianza de la geométrica (agregarla a la geom después de editar todo y hacerlo más breve)
%\begin{equation}
%Var(X)=E(X^2)-{(EX)}^2=\frac{q(1+q)}{p^2}-{(\frac{q}{p})}^2=\frac{q}{p^2}
%\end{equation}
%Varianza de la geométrica (lo mismo)
%\begin{equation}
%Var(X)=E(X^2)-{(EX)}^2=(n(n-1)p^2+np)-(np)^2=np(1-p).
%\end{equation}
%Una variable aleatoria $X$ tiene \emph{distribución de Poisson} (denotada $X\sim Pois(\lambda)$) con el parámetro $\lambda$, cuando $\lambda > 0$ si la PMF de $x$ es
%\begin{equation}
%P(X=k)=\frac{e^{-\lambda}\lambda^k}{k!}, k=0,1,2,\ldots.
%\end{equation}
%Varianza de la distribución de Poisson es
%\begin{equation}
%Var(X)=E(X^2)-{(EX)}^2=\lambda(1+\lambda)-\lambda^2=\lambda
%\end{equation}
