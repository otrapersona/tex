\documentclass[letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\author{Victor Matus}
\title{Protocolo}
\date{\today}
%>>> Mate, símbolos
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{newtxmath} % fuente?
\usepackage{array}
\usepackage{multirow} % tablas
\usepackage{tabularx} % tablas
%<<< Mate, símbolos
\usepackage[dvipsnames]{xcolor} % marcatextos, se puede ir al final?
%>>> Bibliografía
\usepackage{csquotes} % citar
%\usepackage[backend=biber,style=alphabetic,sorting=nyt]{biblatex} % OVERLEAF
%\addbibresource{bibfile.bib} % OVERLEAF
\usepackage[backend=bibtex,style=alphabetic]{biblatex} % genérico no-overleaf
\bibliography{pro} % genérico no-overleaf
%>>>  Bibliografía
%>>> Imágenes
\usepackage{graphicx} % insertar
\usepackage{float} % ubicación flotante
%>>> Imágenes
\begin{document}
\maketitle
\begin{abstract}
    Computer
    \begin{figure}[h]
        \centering\includegraphics[width=.125\textwidth]{computer}
        \caption{Una computadora}
        \label{fig:1}
    \end{figure}

Observe \ref{fig:1}
\end{abstract}
\pagebreak
\tableofcontents
\renewcommand{\listfigurename}{Índice de figuras (imágenes, fotos, \includegraphics[width=1em]{shrug})}
\listoffigures{AKA imágenes}
\listoftables{AKA plots, gráficas, charts}
\section {incompleto}\ \\
* Introduction to Probability:\\
-terminar Expectations\\
-Continuous rand var\\
* Linear Models and the Relevant Distributions and Matrix Algebra:\\
-intervalos confianza, pruebas hipótesis\\
* Bayesian Reasoning and Machine Learning: - checar este libro\\
* ML, NLP: Definición, Tipos\\
*Hipótesis y Objetivos: hipo, gral, part
\pagebreak
%ya no usé esta tabla $=\big($
%\begin{center}
%\begin{tabular}{|| m{1.1cm} | m{1.1cm} || m{1.3cm} | m{1.3cm} || m{1.7cm} %| m{1.7cm} ||}
%\hline
%\multicolumn{1}{|| c |}{código} & \multicolumn{1}{ c ||}{CHAR} & %\multicolumn{1}{ c |}{fecha} & \multicolumn{1}{ c ||}{DATE} & %\multicolumn{1}{ c |}{estado} & \multicolumn{1}{ c ||}{INTEGER}\\
%\hline
%\hline
%\multicolumn{1}{|| c |}{MX01} & \multicolumn{1}{ c ||}{\ } & %\multicolumn{1}{ c |}{2020-01-01} & \multicolumn{1}{ c ||}{\ } & %\multicolumn{1}{ c |}{1} & \multicolumn{1}{ c ||}{\ }\\
%\hline
%\multicolumn{1}{|| c |}{MX02} & \multicolumn{1}{ c ||}{\ } & %\multicolumn{1}{ c |}{2020-01-02} & \multicolumn{1}{ c ||}{\ } & %\multicolumn{1}{ c |}{1} & \multicolumn{1}{ c ||}{\ }\\
%\hline
%\multicolumn{1}{|| c |}{MX03} & \multicolumn{1}{ c ||}{\ } & %\multicolumn{1}{ c |}{2020-01-03} & \multicolumn{1}{ c ||}{\ } & %\multicolumn{1}{ c |}{0} & \multicolumn{1}{ c ||}{\ }\\
%\hline
%\end{tabular}
%\end{center}
\section {Marco teórico}
\subsection {Modelo de base de datos relacional}
El modelo relacional de base de datos, según Date \fullcite{date12} consiste en cinco componentes:
\begin{enumerate}
    \item Una colección de tipos escalares, pueden ser definidos por el sistema (INTEGER, CHAR, BOOLEAN, etc.) o por el usuario.
    \item Un generador de tipos de relaciones y un intérprete para las relaciones mismas.
    \item Estructuras para definir variables relacionales de los tipos generados.
    \item Un operador para asignar valores de relación a dichas variables.
    \item Una colección relacionalmente completa de operadores relacionales genéricos para derivar obtener valores relacionales de otros valores relacionales.
\end{enumerate}
Es importante comenzar definiendo los tipos, ya que las relaciones se definen sobre ellos, según Date, los tipos son ``en esencia un conjunto finito de valores nombrado-todos los valores posibles de alguna categoría específica, por ejemplo, todos los números enteros posibles, todos los caracteres string posibles, todos los teléfonos de proveedores posibles, todos los documentos XML posibles, todas las relaciones con cierta cabecera posibles(y así sucesivamente)'' \cite{date12}.

Cada atributo de cada relación es definido como de un tipo. Los atributos son pares ordenados de combinaciones atributo-nombre/tipo-nombre y una tupla es un par ordenado de atributos.
El modelo relacional también soporta varios tipos de llaves, que poseen las propiedades de unicidad, ninguna contiene dos tuplas distintas con el mismo valor e irreductibilidad, ningún subconjunto suyo es tiene unicidad. La llave foránea (\emph{FK}) es una combinación o set se atributos FK en una relación $r2$ tal que se requiere que cada valor FK sea igual a algún valor de alguna llave K en alguna relación $r1$ ($r1$ y $r2$ no son necesariamente distintos).

Una restricción de integridad (\emph{constraint}) es una expresión booleana que debe evaluarse como verdadera. Los constraints de tipo definen los valores que constituyen un tipo dado, mientras que los constraints de base de datos limitan los valores que pueden aparecer en cierta base de datos. Las bases de datos suelen tener múltiples constraints específicos, expresados en términos de sus relaciones, sin embargo, el modelo relacional incluye dos constraints genéricos, que aplican a cada base de datos:
\begin{itemize}
    \item Regla de integridad de identidad: Las llaves primarias no pueden ser nulas (\emph{null}).
    \item Regla de integridad de referencia: No debe haber valores FK sin relación (si $B$ referencia a $A$, $A$ debe existir).
\end{itemize}

La manipulación de bases de datos relacionales se basa en el álgebra relacional dando la colección de operadores que pueden aplicarse a las relaciones, por ejemplo diferencia (\emph{MINUS}). El operador de asignación relacional, permite se le asigne valor de alguna expresión regular a alguna relación, por ejemplo $r1$ MINUS $r1$ cuando $r1$ y $r2$ son relaciones.
\subsection {Correlación lineal}
Cuando se tiene una variable controlada $x$ y una dependiente $y$ tenemos el modelo lineal
\begin{equation}
Y=\beta_0+\beta_1x+\epsilon
\end{equation}
que implica entonces el modelo para análisis de rendimiento promedio:
\begin{equation}\label{eq:EQ1}
E(Y)=\beta_0+\beta_1x.
\end{equation}

Si la variable $x$ es un valor observado de una variable $X$, al establecerse una relación funcional y al basarse en \eqref{eq:EQ1}
se implica el modelo
\begin{equation}
E(Y|X=x)=\beta_0+\beta_1x
\end{equation}
que supone el valor esperado condicional de $Y$ para un valor fijo de $X$ en una función lineal del valor $x$. Al suponer que la variable aleatoria vectorial $(X, Y)$ tiene una distribución normal bivariable con $E(X)=\mu_X, E(Y)=\mu_Y, V(X)=\sigma^2_X, V(Y)=\sigma^2_Y$, el coeficiente de correlación $\rho$ puede demostrar que
\begin{equation}
E(Y|X=x)=\beta_0+\beta_1x,\qquad donde\ \beta_1=\frac{\sigma_Y}{\sigma_X}\rho.
\end{equation}

Si $(X, Y)$ tiene una distribución normal bivariable, entonces la prueba de independencia es equivalente a probar si el coeficiente de correlación $\rho$ es igual a cero. Denotando con $(X_1, Y_1), (X_2, Y_2),\ldots , (X_n, Y_n)$ una muestra de aleatoria de distribución normal bivariante. El estimador de máxima probabilidad de $\rho$ está dado por el coeficiente de correlación muestral:
\begin{equation}
r=\frac{\sum_{i=1}^{n}(X_i-\overline{X})(Y_i-\overline{Y})}{\sqrt{\sum_{i=1}^{n}(X_i-\overline{X})^2\ \sum_{i=1}^{n}(Y_i-\overline{Y})^2}}.
\end{equation}

Puede expresarse $r$ en términos de cantidades conocidas:
\begin{equation}
r=\frac{S{xy}}{\sqrt{S{xx}S{yy}}}=\hat{\beta}\sqrt{\frac{S{xx}}{S{yy}}}.
\end{equation}

Cuando $(X, Y)$ tenga una distribución normal bivariable, se sabe que
\begin{equation}
E(Y|X=x)=\beta_0+\beta_1x,\qquad donde\ \beta_1=\frac{\sigma_Y}{\sigma_X}\rho.
\end{equation}

Pruebas en las que los conjuntos de hipótesis que contienen $\beta_1$, por ejemplo, $H_a\colon \beta_1 = 0$ contra $H_a\colon \beta_1 > 0$ $H_a\colon \beta_1 < 0$, así como $H_a\colon \beta_1 > 0$ contra $H_a\colon \beta_1 \neq 0$ pueden estar basadas en el estadístico
\begin{equation}
t=\frac{\hat{\beta_1}-0}{S/\sqrt{S{xx}}},
\end{equation}

Wackerly, Mendenhall III y Scheaffer consideran que \fullcite[``parecería lógico usar $r$ como estadístico de prueba para probar hipótesis más generales acerca de $\rho$, pero la distribución de probabilidad para $r$ es difícil de obtener."][]{wack09} Sin embargo, en muestras moderadamente grandes podemos probar la hipótesis $H_0\colon \rho_1=\rho_0$ con una prueba Z en la que
\begin{equation}
Z=\frac{(\frac{1}{2})\ln({\frac{1+r}{1-r})}-(\frac{1}{2})\ln(\frac{1+\rho}{1-\rho})}{\frac{1}{\sqrt{n-3}}}.
\end{equation}

Si $\alpha$ es la probabilidad deseada de cometer un error tipo I, la forma de la región de rechazo depende de la hipótesis alternativa. Las diversas alternativas de interés más frecuente y correspondientes regiones de rechazo son las siguientes:
\begin{equation}  
\begin{matrix}
H_a\colon\rho>\rho0, &RR\colon z>z_\alpha\ \ \ \ \ \ \\
H_a\colon\rho<\rho0, &RR\colon z<-z_\alpha\ \ \ \ \\
H_a\colon\rho\neq\rho0, &RR\colon | z | >z_\alpha/2
\end{matrix}
\end{equation}

La suma de los cuadrados del error \emph{SSE}, es es una alternativa para medie la variación en valores que permanecen sin explicación después de usar las $x$ para ajustar el modelo de regresión lineal simple, la razón $SSE/S_{yy}$ la proporción de la variación total en las $y_i$ que este modelo no explica. El coeficiente de determinación se puede escribir como
\begin{equation}
r^2=(\frac{S_{xy}}{\sqrt{S_{xx}S_{yy}}})^2=(\frac{S_{xy}}{S_{xx}})(\frac{S_{xy}}{S_{yy}})=(\frac{\hat{\beta_1}S_{xy}}{S_{yy}})=\frac{S_{yy}-SEE}{S_{yy}}=1-\frac{SSE}{S_{yy}}.
\end{equation}



Podemos interpretar a $r^2$ como la proporción de la variación total en las $y_i$  que es explicada por una variable $x$ en un modelo de regresión lineal simple.

\subsection {Probabilidad condicional}
La probabilidad condicional tiene las mismas características que la probabilidad, pero $P(\cdot|B)$ actualiza nuestra incertidumbre acerca de los eventos para reflejar la evidencia observada en $B$.

Si $A$ y $B$ son eventos con $P(B)>0$ entonces la \emph{probabilidad condicional} de $A$ dado $B$ denotado por $P(A|B)$, se define como
\begin{equation}
P(A|B)=\frac{P(A\cap B)}{P(B)}.
\end{equation}

Se denomina probabilidad a priori de $A$ a $P(A)$ y probabilidad a posteriori de $A$ a $P(A|B)$ y es importante mencionar que $P(A|B) \neq P(B|A)$.

La probabilidad condicional es la razón de dos probabilidades y sus consecuencias, la primera de ellas se obtiene moviendo el denominador en la definición al otro lado de la ecuación, para cada evento {A} y {B} con posibilidades positivas,
\begin{equation}\label{eq:EQ2}
P(A\cap B)=P(B)P(A|B)=P(A)P(B|A).
\end{equation}
se le conoce como teorema de la \emph{probabilidad de la intersección de dos eventos}. Aplicando repetidamente el teorema \eqref{eq:EQ2} aplicado a la intersección de $n$ eventos obtenemos el teorema de \emph{probabilidad de la intersección de $n$ eventos}. Para cualquier evento $A_1,\ldots,A_n$ con probabilidad $P(A_1,A_2,\ldots,A_{n-1})>0$,
\begin{equation}
\begin{matrix}
P(A_1,A_2,\ldots,A_n)=P(A_1)P(A_2|A_1) \qquad \qquad \qquad \qquad \qquad \\
\qquad  \qquad \qquad \qquad \qquad P(A_3|A_1,A_2)\ldots P(A_n|A_1,\ldots,A_{n-1}).\end{matrix}
\end{equation}

Otro teorema que relaciona a $P(A|B)$ con $P(B|A)$ es la regla \emph{regla de Bayes}:
\begin{equation}
P(A|B)=\frac{P(B|A)P(A)}{P(B)}
\end{equation}
que se origina directamente del teorema \eqref{eq:EQ2} y a su vez se origina directamente de la definición de probabilidad condicional, sin embargo, la regla de Bayes tiene importantes aplicaciones e implicaciones en probabilidad y estadística, ya que en ocasiones es más fácil encontrar $P(B|A)$ que $P(A|B)$ o viceversa. Otra forma de escribir la regla, es en términos de apuestas (\emph{odds}), las odds de un evento $A$ son
\begin{equation}
odds(A)=P(A)\frac{P(A)}{P(A^\text{c})}.
\end{equation}
Al tomar la expresión $P(A|B)$ y dividirla entre $P(A^\text{c}|B)$, ambos de la regla de Bayes; llegamos al \emph{teorema de Bayes en forma de apuestas}: para cualquier evento $A$ y $B$ con posibilidades positivas, las odds de $A$ \colorbox{yellow}{after conditioning on} $B$ son
\begin{equation}
\frac{P(A|B)}{P(A^\text{c}|B)}=\frac{P(B|A)}{P(B|A^\text{c})}\frac{P(A)}{P(A^\text{c})}.
\end{equation}
En este caso las odds a posteriori $P(A|B)/P(A^\text{c}|B)$ son iguales a las odds a priori $P(A)/P(A^\text{c})$ por el factor $P(B|A)/P(B|A^\text{c})$ lo que se le conoce en estadística como \emph{función de verosimilitud}.

La ley de Bayes es usada en ocasiones en conjunto con la \emph{ley de probabilidad total}, que es es esencial para descomponer problemas complicados de probabilidad en problemas partes: Si $A_1,\ldots,A_n$ es una partición de una muestra del espacio $S$, con $P(A_i)>0$ para todo $i$, entonces
\begin{equation}
P(B)=\sum_{i=1}^{n}P(B|A_i)P(A_i).
\end{equation}
Prueba: como los $A_i$ forman una partición de $S$, podemos descomponer $B$ como
\begin{equation}
B=(B\cap A_1)\cup(B\cap A_2)\cup\ldots\cup(B\cap A_n).
\end{equation}
como las partes están disjuntas, podemos agregar sus posibilidades para obtener $P(B)$:
\begin{equation}
P(B)=P(B\cap A_1)+P(B\cap A_2)+\ldots+P(B\cap A_n).
\end{equation}
Aplicando el teorema \eqref{eq:EQ2} a cada $P(B\cap A_i)$ obtenemos
\begin{equation}
P(B)=P(B|A_1)P(A_1)+\ldots+P(B|A_n)P(A_n).
\end{equation}
La \emph{ley de probabilidad total} dice que para obtener la probabilidad incondicional de $B$, tenemos que dividir el espacio muestra en cortes disjuntos $A_i$, encontrar la probabilidad condicional de $B$ en cada corte, después tomar la suma ponderada de las probabilidades condicionales, donde los pesos son las probabilidades $P(A_i)$.
\subsection {Variables aleatorias y sus distribuciones}
Una \emph{variable aleatoria} es una función asignando un número real $\mathbb{R}$ a cada posible resultado de un experimento. Con una muestra en espacio $S$, una variable aleatoria $X$ asigna el valor numérico $X(s)$ a cada resultado posible $s$ del experimento. La aleatoriedad viene del hecho que tenemos un experimento aleatorio (con probabilidades descritas por la función de probabilidad $P$). Las variables aleatorias simplifican la notación y expanden la habilidad de cuantificar y resumir resultados de experimentos.

Se dice que una variable $X$ es discreta cuando si hay una lista finita de valores $a_,a_2,\ldots,a_n$ o un una lista infinita de valores $a_,a_2,\ldots$ de tal forma que $P(X=a_j$ para algún $j)=1$. Si $X$ es una variable aleatoria discreta, entonces el conjunto infinito o contable de valores $x$ tal que $P(X=x)$ se llama \emph{soporte} de $X$. En contraste una variable aleatoria continua puede tomar cualquier valor real en un intervalo.
\subsubsection {Función de probabilidad}
La forma más natural de expresar la distribución de variables aleatorias discretas es la \emph{función de probabilidad}\cite{blitz19} \colorbox{yellow}{(PMF, por sus siglas en inglés?)} que, para una $X$ discreta, es la función $p_X$ dada por $p_X(x)=P(X=x)$. El teorema de \emph{funciones de probabilidad válidas} dice que cuando $X$ es una variable aleatoria con soporte $x1,x2,\ldots$, la función de probabilidad $p_X$ de $x$ debe satisfacer los siguiente criterios:
\begin{itemize}
    \item No negativo $p_X (x) > 0$ si $x=x_j$ para un $j$, y $p_X(x)=0$, de otra forma;
    \item Suma 1: $\sum_{j=1}^{\infty}p_X(x_j)=1$.
\end{itemize}
el primer criterio es verdadero porque la probabilidad es no negativa, el segundo es verdadero ya que $X$ debe tomar \emph{algún} valor, y los eventos ${X=xj}$ están disjuntos, entonces
\begin{equation}
\sum_{j=1}^{\infty}P(X=x_j)=P\bigg(\bigcup_{j=1}^{\infty}\{X=x_j\}\bigg)=P(X=x_1\ \text{ó}\ X=x_2\ \text{ó}\ \ldots)=1.
\end{equation}
\subsubsection {Distribución de Bernoulli y binominal}
Una variable aleatoria tiene la \emph{distribución de Bernoulli} con un parámetro $p$ si $P(X=1)=p$ y $P(X=0=1-p)$, cuando $0<p<1$. Se escribe como $X \sim Bern(p)$, el símbolo $\sim$ significa ``distribuido como'' y la probabilidad $p$ es el \emph{parámetro}, que determina qué distribución de Bernoulli específica tenemos.

Supóngase que se realizan $n$ ensayos Bernoulli independientes, cada uno con probabilidad $p$ de éxito. $X$ sea el número de éxitos, la distribución $X$ se llama \emph{distribución binominal} con parámetros $n$ y $p$; se escribe $X \sim Bin(p,n)$.
$Bern(p)$ es la misma distribución que $Bin(1,p)$. Bernoulli es un caso especial de binominal, si $x \sim Bin(1,p)$, entonces la función de probabilidad de $X$ es
\begin{equation}
P(X=k)=\binom{n}{k}p^k(1-p)^{n-k}
\end{equation}
para $k=0,1,\ldots,n$ (y por otra parte $P(X=k)=0$). 
\subsubsection {Distribución de hipergeométrica}
Si $X \sim HGeom(w,b,n)$, entonces la función de probabilidad de X es
\begin{equation}
P(X=k)=\frac{\binom{w}{k}\binom{b}{n-k}}{\binom{w+b}{n}},
\end{equation}
para enteros $k$ satisfaciendo $0\leq k\leq w$ y $0\leq n-k\leq b$, y $P(X=k)=0$. La estructura esencial de la distribución hipergeométrica se basa en que objetos en su población están clasificados usando dos tipos de etiquetas, al menos una de estas siendo asignada al azar.
Las distribuciones $HGeom(w,b,n)$ y $HGeom(n,w+b-n,1)$ son idénticas si $X$ y $Y$ tienen la misma distribución, podemos demostrarlo algebraicamente:
\begin{equation}
P(X=k)=\frac{\binom{w}{k}\binom{b}{n-k}}{\binom{w+b}{n}}=\frac{w!b!n!(w+b-n)!}{k!(w+b)!(w-k)!(n-k)!(b-n+k)!}
\end{equation}
\begin{equation}
P(X=k)=\frac{\binom{n}{k}\binom{w+b-n}{w-k}}{\binom{w+b}{w}}=\frac{w!b!n!(w+b-n)!}{k!(w+b)!(w-k)!(n-k)!(b-n+k)!}.
\end{equation}%if intro for bernolli and hyper neede, 3.4.6 has a bit a few useful lines
\subsubsection {Distribución uniforme discreta}
Teniendo $C$, un conjunto finito no vacío de números, se elige un número uniformemente al azar (o sea que todos los números tienen la misma posibilidad de ser elegidos), llámese $X$. Entonces se dice que $X$ una \emph{distribución uniforme discreta} con el parámetro $C$. Se dice entonces que la función de probabilidad de $X \sim DUNif(C)$ (la distribución uniforme discreta de $X$) es
\begin{equation}
P(X=x)=\frac{1}{|C|}
\end{equation}
para $x \in C$ (de lo contrario $0$) ya que la función de probabilidad debe sumar 1.
\subsubsection {Función de distribución acumulada}
Esta función describe la distribución de todas las variables aleatorias (a diferencia de la función de probabilidad que sólo se aplica a las discretas). La \emph{función de distribución acumulada} de una variable aleatoria $X$ es la función $F_X$ dada por $F_X(x)=P(X\leq x)$ y tiene las siguientes propiedades:
\begin{itemize}
    \item Incrementos: Si $x_1\leq x_2$, then $F(x_1)\leq F(x_2)$.
    \item Continua por la derecha: Es continua por la posibilidad de tener saltos. Cuando hay saltos es continua por la derecha, es decir, por cada $a$ se tiene
    \begin{equation}
    F(a)=\lim_{c\to a^+}F(x).
    \end{equation}
    \item Convergencia de $0$ y $1$ en los límites
    \begin{equation}
    \lim_{x\to \infty}F(x)=0\ \ \text{y}\ \lim_{x\to \infty}F(x)=1.
    \end{equation}
\end{itemize}
\subsection {Valor esperado}
Mientras que las distribuciones anteriores nos han dado toda la información acerca de la probabilidad de las variables aleatorias, cuando sólo se requiere un número que extraiga su valor, podemos utilizar la \emph{media}, también conocida como \emph{valor esperado}. Dada una lista de números $x_1,x_2.\ldots,x_n$, para obtener la \emph{media aritmética}, estos se suman y dividen entre $n$:
\begin{equation}
\bar{x}=\frac{1}{n}\sum_{j=1}^{n}x_j,
\end{equation}
la \emph{media ponderada} de $x_1,x_2.\ldots,x_n$ se obtiene de la siguiente forma:
\begin{equation}
\text{media ponderada}(x)=\frac{1}{n}\sum_{j=1}^{n}x_jP_j,
\end{equation}
donde los pesos $p_1,p_2.\ldots,p_n$ son números no negativos previamente especificados que suman a $1$.

El valor esperado o media de una variable aleatoria discreta $X$ cuyos posibles valores distintos son $x_1,x_2.\ldots$ es definida por
\begin{equation}
E(X)=\sum_{j=1}^{\infty}x_jP(X=xj),
\end{equation}
si el soporte es finito, entonces se reemplaza por una suma finita, escribiéndose de la siguiente forma:
\begin{equation}
E(X)=\sum_{x}\underbrace{x}_\text{valor}\underbrace{P(X=x)}_{\begin{matrix}^\text{Función de}\\^\text{probabilidad}\\^\text{en $x$}\end{matrix}}.
\end{equation}

El valor esperado de una suma de variables aleatorias es la suma de sus valores esperados individuales, este es el teorema de la \emph{linealidad del valor esperado}, donde para cada variable aleatoria $X,Y$ y cada constante $c$,
\begin{equation}
\begin{matrix}
E(X+Y)=E(X)+E(Y),\\
E(cX)=cE(X).
\end{matrix}
\end{equation}
\subsubsection {Binominal geométrica y negativa}
Distribución geométrica: Se tiene una secuencia de ensayos independientes Bernoulli, cada uno con la misma probabilidad de éxito $p\in(0,1)$, con ensayos realizados hasta que se alcanza el éxito. $X$ es el número de \emph{fallas} antes de la primera prueba exitosa por lo que $X$ tiene una \emph{distribución geométrica} con un parámetro $p$; denotado $X\sim Geom(p)$. Con esto podemos llegar a los teoremas de \emph{distribución geométrica de la función de probabilidad}, cuando $X\sim Geom(p)$, entonces la función de probabilidad de $X$ será
\begin{equation}
P(X=k)=q^kp
\end{equation}
para $k=1,2,\ldots,$ cuando $q=1-p$; y el teoremas de \emph{distribución geométrica de la función de distribución acumulativa}, cuando $X\sim Geom(p)$, entonces la función de distribución acumulativa de $X$ será
    \begin{equation}
    F(x)=
    \begin{cases}
    1-q^{\lfloor x\rfloor+1}, \text{ si } x\geq 0;\\
    0, \text{ si }x < 0,
    \end{cases}
    \end{equation}
cuando $q=1-q$ y $\lfloor x\rfloor$ es el mayor entero y menor o igual a $x$.

El valor esperado geométrico de $X\sim Geom(p)$ es
\begin{equation}
E(X)=\sum_{k=0}^{\infty}kq^kp,
\end{equation}
cuando $q=1-p$. Aunque esta no es una serie geométrica, podemos llegar a ello
\begin{equation}\begin{matrix}
\sum_{k=0}^{\infty}q^k=\frac{1}{1-q}\\
\\
\sum_{k=0}^{\infty}kq^{k-1}=\frac{1}{{1-q}^2},
\end{matrix}
\end{equation}
finalmente multiplicamos ambos lados por $pq$, recuperando la suma original que queríamos encontrar
\begin{equation}
E(X)=\sum_{k=0}^{\infty}kq^kp=pq\sum_{k=0}^{\infty}kq^{k-1}=pq\frac{1}{{(1-q)}^2}=\frac{q}{p}.
\end{equation}
Primer valor esperado de éxito \emph{FS}, podemos definir a $Y\sim FS(p)$ como $Y=X+1$ donde $X\sim Geom(p)$, por lo que tenemos
\begin{equation}
E(Y)=E(X+1)=\frac{q}{p}+1=\frac{1}{p}.
\end{equation}

Las \emph{distribuciones binominales negativas} generalizan la distribución geométrica en lugar de esperar por un éxito, podemos esperar por cualquier número predeterminado $r$ de éxitos. En una secuencia de ensayos independientes Bernoulli con probabilidad de éxito $p$, si $X$ es el número de \emph{fallas} antes del éxito número $r$, entonces se dice que $X$tiene una distribución binominal negativa con parámetros $r$ y $p$, denotado $X\sim NBin(r,p)$.

La distribución binominal cuenta el número de éxitos en un número fijo de ensayos, mientras que la binominal negativa cuenta el número de fallas hasta alcanzar cierto número de éxitos. Si $X\sim NBin(r,p)$, entonces la función de probabilidad de $X$ es
\begin{equation}
P(X=n)=\binom{n+r-1}{r-1}p^rq^n
\end{equation}
para $n=0,1,2\ldots,$ donde $q=1=p$.
\subsubsection{LOTUS}
La \emph{ley del estadista inconsciente} (\emph{LOTUS}, por sus siglas en inglés) permite calcular $E(g(X))$ directamente usando la distribución de $X$, sin tener que encontrar la distribución de $g(X)$ primero: si $X$ es una variable discreta y $g$ es una función de $\mathbb{R}$ a $\mathbb{R}$, entonces
\begin{equation}
E(g(X))=\sum_{x}g(x)P(X=x),
\end{equation}
donde la suma se toma de todos los valores posibles de $X$. El valor esperado de $g(X)$ puede ser escrito en forma no agrupado como
\begin{equation}
E(g(X))=\sum_{s}g(X(s))p(\{s\}).
\end{equation}
\subsubsection{Varianza}
Pág 171, 4.6
\section {Objetivos}
Comenzar desde cero cada proyecto es ineficiente. (esto es temporal)
\subsection {General}
Diseñar y desarrollar una\\
plataforma/framework de ML para NLP\\
reutilizable y/o de uso general/ ¿para casos de uso similares?
\subsection {Particulares}
Revisé algunas tesis para darme la idea, necesito saber un poco más del tema para desarrollar esta parte, creo que sería algo así:
\begin{enumerate}
    \item Investigación
    \item Análisis info
    \item Diseño/desarrollo
    \item Comprobación
\end{enumerate}
\subsection {Hipótesis}
Al integrar\\
/tecnologías/técnicas/modelos/librerías/frameworks/\\
de RDB, ML, NLP, ¿transfer learning?, ¿deep learning?,...\\
se de puede /diseñar/desarrollar/, ¿e implementar? una\\
/plataforma/framework/\\
/genérica/normalizada/universal/reutilizable/estandarizada/compatible\\
/con/en/para/ /casos de uso similares/diversos casos de uso/\\
(/reduciendo tiempo/ahorrando recursos/.) estas oración se sale del scope

\section {Metas}
Contribuir por medio del diseño y desarrollo de la\\
/plataforma/framework/ de ML para NLP\\
que será utilizable en variedad de casos reales /con características similares./
\section {Metodologías}

\newpage
\section {Referencias}
\printbibliography[heading=none]
\end{document}
